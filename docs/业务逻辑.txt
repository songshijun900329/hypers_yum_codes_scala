业务逻辑：

### 业务逻辑:

1. 消费Kafka中的标签数据，对每条数据进行处理:
2. 【查询人群规则列表】查询人群Hbase中，全表查，查出的list中，筛选matchInfo.orderTime在startTime和endTime之间的人群列表，为激活状态的人群
3. 【去重已发数据】对于每条人群规则，拼接Kafka消息中的MD5(userCode) + _ + 人群规则的crowdCode,去人群结果Hbase表(swift:dws_crowd_sink)中，
查询是否已经存在人群结果，对于已经存在人群结果的人群规则，从人群规则列表中去除该人群规则，生成去重后的人群规则列表（防止对于下游的重复推送）
4. 【查询标签结果列表】按照rowkey前缀MD5(userCode), 查询Hbase(swift:dws_label_sink)中的该用户的所有标签结果
5. 【过滤标签结果列表】对于每3.中的每个人群规则，对标签结果列表，进行预过滤：选取标签orderTime在人群startTime和endTime之间的标签，生成过滤后的标签结果列表
6. 【规则判断】将5.中的的标签列表，进行与或关系的处理，生成人群结果（第一期可以只做最外层的与逻辑关系）
7. 【结果推送】将人群结果列表，推送到Kafka和Hbase中


### 

------------------------------------------------------------------------------------------------------------------------

PS：
【步骤二】：
先检索出人群规则表（swift:dim_crowd_src）的所有数据，
遍历list，
list里的起止时间（startTime、endTime）
能覆盖kafka标签结果数据的订单时间（orderTime）的留下，不能覆盖的滤掉



input：
（1）kafka数据（标签结果数据）
（2）HBASE数据（人群规则数据）
output：
（1）人群规则数据LIST

------------------------------------------------------------------------------------------------------------------------

【步骤三】：
rowkey规则：
遍历[步骤二]输出的人群规则LIST，对list中每一条人群规则的JSON字符串，解析出其中的"crowdCode"，
再对kafka当前这一帧数据中的"userCode"，按照：MD5(userCode) + _ + crowdCode规则进行拼接，
形成rowkey

去[步骤二]输出的人群规则list做去重：
人群规则list - Hbase中查出来的有数的

input：
（1）[步骤二的output]人群规则LIST
（2）按指定rowkey，从人群结果Hbase表(swift:dws_crowd_sink)中查出来的数据
output：
（1）人群规则LIST（去重后的list）

------------------------------------------------------------------------------------------------------------------------

【步骤四】：
rowkey规则：
对kafka中标签结果JSON数据进行解析，得到"userCode"，对其取MD5作为rowkey"前缀"（PS：因为是前缀所以扫出来是一个HBASE的resultList）

使用该rk查询HBASE表(swift:dws_label_sink)获得该用户的所有标签结果的LIST

input：
（1）kafka中标签结果数据
（2）HBASE中标签结果数据
output：
（1）根据rowkey前缀模糊查询HBASE表（标签结果表）查出来的resultLIST（标签结果LIST）

------------------------------------------------------------------------------------------------------------------------

【步骤五】：
过滤规则：
外层遍历[步骤三的输出]人群规则LIST中的每个人群规则，对标签结果列表，进行预过滤：
内层遍历[步骤四的输出]标签结果LIST中的每个标签结果，
选取标签结果数据："orderTime"
在人群规则数据："startTime" 和 "endTime"
时间范围内的标签结果数据，留下，不在时间范围内的标签结果数据被舍弃，
从而生成过滤后的标签结果LIST

PS:
步骤五的逻辑看似和步骤二是一样的，但是步骤二过滤的是"人群规则LIST"，而这个步骤五过滤的是"标签结果LIST"，
所以，逻辑一样，但是逻辑作用的LIST是不一样的。

input：
（1）[步骤三的输出]人群规则LIST
（2）[步骤四的输出]标签结果LIST
output：
（1）标签结果LIST（过滤后的list）--> 数据结构为：Map(crowcode,LIST(标签结果))

PS：
这里的map.size == "人群规则LIST".size，
也就是每个"人群规则LIST"中的element，都可封装为一个JsonObject，封装为Map的key

------------------------------------------------------------------------------------------------------------------------

【步骤六】：
转化逻辑：
Map(crowcode,LIST(标签结果))

1）人群结果 = 人群规则一些key + kafka中的标签结果的matchinfo；
2）遍历Map中的每个key，也就是每条人群规则，根据人群规则作用在key对应的value（标签结果LIST）所返回的true/false，来决定当前遍历到的map的key是否留下，
如果为true，map的key（该条人群规则）留下，否则过滤掉；
3）如何根据人群规则判断true/false呢？
"subRules"的叶子节点中：
{
"logic": null,--
"subRules": [],
"labelId": "label-1"
}
"labelId"在"标签结果LIST"中的"labelId"中存在对应值，则该json对象为true，否则为false。
而没一个叶子节点都计算完true/false后，按照"logic"的取值是"and"或"or"，对所有叶子节点的真假返回值进行取"与"/"或"运算，得到最后的true/false值。
最后的与或逻辑后获得的true/false值来决定当前MAP的key是否留下还是过滤掉；
4）如果留下，则该人群结果取一部分key值+从当前kafka的标签结果的matchinfo中取一些值=拼成该人群规则对应的人群结果；
5）没一个被留下的map的key最后都拼出了一条人群结果，封装成一个"人群结果LIST"
6）"人群结果LIST" --> sink到HBASE


input：
（1）[步骤五的输出]Map(crowcode,LIST(标签结果))
output：
（1）人群结果LIST（根据人群规则的与或逻辑进行转化）

















































